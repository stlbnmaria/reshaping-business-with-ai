{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/transactions_dataset.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date_order\"] = pd.to_datetime(df[\"date_order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clients = df.client_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df[df.sales_net > 0].copy()\n",
    "df_ml = pd.concat(\n",
    "    [df_ml, pd.get_dummies(df_ml[\"order_channel\"], dtype=int)], axis=1\n",
    ")\n",
    "df_ml[\"nr_orders\"] = 1\n",
    "df_ml = df_ml.drop(\n",
    "    columns=[\"date_invoice\", \"branch_id\", \"order_channel\", \"product_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df_ml.groupby([\"date_order\", \"client_id\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stamp = df_sum.date_order.max() - timedelta(days=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_test = df_sum[df_sum.date_order >= test_stamp].client_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame({\"client_id\": all_clients})\n",
    "y_test[\"churn\"] = ~y_test.client_id.isin(customers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stamp = test_stamp - timedelta(days=threshold)\n",
    "X_test = df_sum[\n",
    "    (df_sum.date_order >= train_stamp) & (df_sum.date_order < test_stamp)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(columns=\"date_order\")\n",
    "X_test = X_test.groupby(\"client_id\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all buys ever\n",
    "all_buys_test = (\n",
    "    df_sum.loc[\n",
    "        (df_sum.date_order < test_stamp),\n",
    "        [\"client_id\", \"sales_net\", \"quantity\", \"nr_orders\"],\n",
    "    ]\n",
    "    .groupby(\"client_id\")\n",
    "    .sum()\n",
    ")\n",
    "all_buys_test.columns = [\"perc_sales_net\", \"perc_quantity\", \"perc_nr_orders\"]\n",
    "X_test = X_test.merge(\n",
    "    all_buys_test, left_index=True, right_index=True, how=\"left\"\n",
    ")\n",
    "X_test[\"perc_sales_net\"] = X_test[\"sales_net\"] / X_test[\"perc_sales_net\"]\n",
    "X_test[\"perc_quantity\"] = X_test[\"quantity\"] / X_test[\"perc_quantity\"]\n",
    "X_test[\"perc_nr_orders\"] = X_test[\"nr_orders\"] / X_test[\"perc_nr_orders\"]\n",
    "X_test = X_test.drop(columns=[\"nr_orders\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_buy_time_test = df_sum[df_sum.date_order < test_stamp].copy()\n",
    "# Sort data by 'client_id' and 'date_order'\n",
    "avg_buy_time_test.sort_values([\"client_id\", \"date_order\"], inplace=True)\n",
    "df_day = avg_buy_time_test.drop_duplicates([\"date_order\", \"client_id\"])\n",
    "\n",
    "# Calculate the time difference between consecutive purchases for each customer\n",
    "df_day[\"time_since_previous_purchase\"] = df_day.groupby(\"client_id\")[\n",
    "    \"date_order\"\n",
    "].diff()\n",
    "\n",
    "time_to_buy = (\n",
    "    df_day.groupby(\"client_id\")[\"time_since_previous_purchase\"].mean().dt.days\n",
    ")\n",
    "\n",
    "X_test = X_test.merge(\n",
    "    time_to_buy, left_index=True, right_index=True, how=\"left\"\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_test.merge(y_test, left_index=True, right_on=\"client_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.churn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame({\"client_id\": all_clients})\n",
    "y_train[\"churn\"] = ~y_train.client_id.isin(X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_sum[\n",
    "    (df_sum.date_order >= (train_stamp - timedelta(days=threshold)))\n",
    "    & (df_sum.date_order < train_stamp)\n",
    "]\n",
    "X_train = X_train.drop(columns=\"date_order\")\n",
    "X_train = X_train.groupby(\"client_id\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all buys ever\n",
    "all_buys_train = (\n",
    "    df_sum.loc[\n",
    "        (df_sum.date_order < train_stamp),\n",
    "        [\"client_id\", \"sales_net\", \"quantity\", \"nr_orders\"],\n",
    "    ]\n",
    "    .groupby(\"client_id\")\n",
    "    .sum()\n",
    ")\n",
    "all_buys_train.columns = [\"perc_sales_net\", \"perc_quantity\", \"perc_nr_orders\"]\n",
    "X_train = X_train.merge(\n",
    "    all_buys_train, left_index=True, right_index=True, how=\"left\"\n",
    ")\n",
    "X_train[\"perc_sales_net\"] = X_train[\"sales_net\"] / X_train[\"perc_sales_net\"]\n",
    "X_train[\"perc_quantity\"] = X_train[\"quantity\"] / X_train[\"perc_quantity\"]\n",
    "X_train[\"perc_nr_orders\"] = X_train[\"nr_orders\"] / X_train[\"perc_nr_orders\"]\n",
    "X_train = X_train.drop(columns=[\"nr_orders\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_buy_time_train = df_sum[df_sum.date_order < train_stamp].copy()\n",
    "# Sort data by 'client_id' and 'date_order'\n",
    "avg_buy_time_train.sort_values([\"client_id\", \"date_order\"], inplace=True)\n",
    "df_day = avg_buy_time_train.drop_duplicates([\"date_order\", \"client_id\"])\n",
    "\n",
    "# Calculate the time difference between consecutive purchases for each customer\n",
    "df_day[\"time_since_previous_purchase\"] = df_day.groupby(\"client_id\")[\n",
    "    \"date_order\"\n",
    "].diff()\n",
    "\n",
    "time_to_buy = (\n",
    "    df_day.groupby(\"client_id\")[\"time_since_previous_purchase\"].mean().dt.days\n",
    ")\n",
    "\n",
    "X_train = X_train.merge(\n",
    "    time_to_buy, left_index=True, right_index=True, how=\"left\"\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train.merge(\n",
    "    y_train, left_index=True, right_on=\"client_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.churn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf = LogisticRegression(random_state=0).fit(train.drop(columns=[\"client_id\", \"churn\"]), train[\"churn\"])\n",
    "clf = RandomForestClassifier(random_state=0).fit(\n",
    "    train.drop(columns=[\"client_id\", \"churn\"]), train[\"churn\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test.drop(columns=[\"client_id\", \"churn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(test[\"churn\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "\n",
    "cm = confusion_matrix(test[\"churn\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fpr, tpr, _ = roc_curve(\n",
    "    test[\"churn\"],\n",
    "    clf.predict_proba(test.drop(columns=[\"client_id\", \"churn\"]))[:, 1],\n",
    ")\n",
    "\n",
    "# create ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# Add a random prediction line (diagonal line)\n",
    "random_line = np.linspace(0, 1, num=100)\n",
    "plt.plot(\n",
    "    random_line,\n",
    "    random_line,\n",
    "    linestyle=\"--\",\n",
    "    label=\"Random Prediction Line\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
